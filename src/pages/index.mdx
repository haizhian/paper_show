---
layout: ../layouts/Layout.astro
title: "CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale"       
favicon: "/favicon.svg"
thumbnail: "/screenshot-light.png"
---

import Header from "../components/Header.astro";
import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Image from "../components/Image.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";
import { Image as AstroImage } from "astro:assets";
import PDF from "../components/PDF.astro";
import { ImageComparison } from "../components/ImageComparison.tsx";
import outside from "../assets/outside.mp4";
import Splat from "../components/Splat.tsx";
import dogsDiffc from "../assets/dogs-diffc.png";
import dogsTrue from "../assets/dogs-true.png";
import CodeBlock from "../components/CodeBlock.astro";
import Table from "../components/Table.astro";
import BlueHighlight from "../components/BlueHighlight.astro";
import FigureLightbox from "../components/FigureLightbox.astro";
import xidianLogo from "../assets/xidian_logo.svg";


export const components = { pre: CodeBlock, table: Table };

<Header
  title="CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale"
  logoSrc={xidianLogo.src}
  authors={[
    {
      name: "Xiao Liang",
      url: "https://scholar.google.com/citations?user=OuATjSsAAAAJ&hl=zh-CN",
      institution: "Xidian University, Xi'an, China"
    }
  ]}
  conference="ACM MM 2025"
  links={[
    { name: "Paper", url: "https://arxiv.org/pdf/2507.06959", icon: "ri:file-pdf-2-line" },
    { name: "Code",  url: "https://github.com/ResearchGroup-MedVLLM/CheX-Phi35V", icon: "ri:github-line" },
    { name: "arXiv", url: "https://arxiv.org/abs/2507.06959",  icon: "academicons:arxiv" },
    { name: "Model", url: "https://huggingface.co/HaiZhiYan/CheX-Phi35V/tree/main", icon: "simple-icons:huggingface" },
  ]}
/>

<FigureLightbox
  src="/F1_real_moti.svg"
  alt="Figure 1 Â· Motivation of CheXPO"
  max={2000}
/>
<HighlightedSection>

## Abstract
<p className="text-lg leading-relaxed">
  Vision-language models (VLMs) are prone to hallucinations that critically compromise reliability in medical applications. While preference optimization can mitigate these hallucinations through clinical feedback, its implementation faces challenges such as clinically irrelevant training samples, imbalanced data distributions, and prohibitive expert annotation costs. To address these challenges, we introduce **CheXPO**, a **Che**st **X**-ray **P**reference **O**ptimization strategy that combines <BlueHighlight>confidence-similarity joint mining</BlueHighlight> with <BlueHighlight>counterfactual rationale</BlueHighlight>. Our approach begins by synthesizing a unified, fine-grained multi-task chest X-ray visual instruction dataset across different question types for supervised fine-tuning (SFT). We then identify hard examples through <BlueHighlight>token-level confidence analysis</BlueHighlight> of SFT failures and use <BlueHighlight>similarity-based retrieval</BlueHighlight> to expand hard examples for balancing preference sample distributions, while <BlueHighlight>synthetic counterfactual rationales</BlueHighlight> provide fine-grained clinical preferences, eliminating the need for additional expert input. Experiments show that CheXPO achieves 8.93% relative performance gain using only 5% of SFT samples, reaching state-of-the-art performance across diverse clinical tasks and providing a scalable, interpretable solution for real-world radiology applications.
</p>

</HighlightedSection>
## Method Openreview

Overview of our chest X-ray VLM training pipeline. Our framework leverages visual instruction tuning and preference
alignment, fine-tuning Phi-3.5V with LoRA to obtain a base SFT model. A confidence-similarity joint mining strategy selects
high-value samples, followed by counterfactual rationale construction for preference alignment to reinforce clinical reliability
<Figure>
  <img
    slot="figure"
    src="/Figure3_overview.svg"
    alt="Overview of our CheXPO method"
    class="w-full max-w-[1200px] object-contain mx-auto rounded-lg shadow"
  />
  <span slot="caption">
    Overview of our CheXPO method for chest-X-ray VLM preference optimization.
  </span>
</Figure>

## Image comparison slider

An interactive, accessible slider component with keyboard navigation.
<Figure>
  <ImageComparison slot="figure" client:load imageUrlOne={dogsDiffc.src} imageUrlTwo={dogsTrue.src} altTextOne="Photo of two dogs running side-by-side in shallow water, lossily compressed using the DiffC algorithm" altTextTwo="Original photo of two dogs running side-by-side in shallow water" />
  <span slot="caption">A photo of two dogs running side-by-side in shallow water, lossily compressed using the <a href="https://jeremyiv.github.io/diffc-project-page/">DiffC algorithm</a>.</span>
</Figure>

## Two columns

Use the two columns component to display two columns of content. In this example, the first column contains a figure with a YouTube video and the second column contains a figure with a custom [React](https://react.dev/) component. By default, they display side by side, but if the screen is narrow enough (for example, on mobile), they're arranged vertically.

<TwoColumns>
  <Figure slot="left">
    <YouTubeVideo slot="figure" videoId="wjZofJX0v4M" />
    <span slot="caption">Take a look at this YouTube video.</span>
  </Figure>
  <Figure slot="right">
    <Splat slot="figure" client:idle />
    <span slot="caption">Now look at this <a href="https://en.wikipedia.org/wiki/Gaussian_splatting">Gaussian splat</a>, rendered with a React component.</span>
  </Figure>
</TwoColumns>

## Heading levels

Use headings to divide your content into sections.

### Heading 3

Go down a level to heading 3...

#### Heading 4

...and down again to heading 4.

## LaTeX

You can also add LaTeX formulas, rendered during the build process using [KaTeX](https://katex.org/) so they're quick to load for visitors of your project page. You can write them inline, like this: <LaTeX inline formula="a^2 + b^2 = c^2" />. Or, you can write them as a block:

<LaTeX formula="\int_a^b f(x) dx" />

## Tables

You can add simple tables using [GitHub Flavored Markdown syntax](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/organizing-information-with-tables):

| Model | Accuracy | F1 score | Training time (hours) |
| :--- | :---: | :---: | :---: |
| BERT-base | 0.89 | 0.87 | 4.5 |
| RoBERTa-large | 0.92 | 0.91 | 7.2 |
| DistilBERT | 0.86 | 0.84 | 2.1 |
| XLNet | 0.90 | 0.89 | 6.8 |

## BibTeX citation

```bibtex
@misc{liang2025chexpopreferenceoptimizationchest,
      title={CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale}, 
      author={Xiao Liang and Jiawei Hu and Di Wang and Zhi Ma and Lin Zhao and Ronghan Li and Bo Wan and Quan Wang},
      year={2025},
      eprint={2507.06959},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.06959}, 
}
```